{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "folder_path = '/home/heza7322/PycharmProjects/missing-value-handling-in-carts/data/raw/'\n",
    "output_folder_path = '/home/heza7322/PycharmProjects/missing-value-handling-in-carts/data/cleaned/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# German credit score\n",
    "data_set = 'german.data'\n",
    "raw_data = pd.read_fwf(folder_path + data_set, header = None)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['checking_account_status'] = raw_data[0].str[1:].astype(int).replace({14:np.nan})\n",
    "df['checking_account_status'] -= df['checking_account_status'].min()\n",
    "\n",
    "more_raw_data = raw_data[1].str.split(' ',expand = True)\n",
    "more_raw_data.columns = np.arange(2,more_raw_data.shape[1]+2)\n",
    "\n",
    "df['duration'] = more_raw_data.pop(2).astype(float)\n",
    "df['credit_history'] = more_raw_data.pop(3)\n",
    "df['purpose'] = more_raw_data.pop(4).replace({\n",
    "    'A40': 'car (new)',\n",
    "    'A41': 'car (used)',\n",
    "    'A42': 'furniture/equipment',\n",
    "    'A43': 'radio/TV',\n",
    "    'A44': 'domestic_appliances',\n",
    "    'A45': 'repairs',\n",
    "    'A46': 'education',\n",
    "    'A47': 'vacation',\n",
    "    'A48': 'retraining',\n",
    "    'A49': 'business',\n",
    "    'A410': 'others'\n",
    "})\n",
    "\n",
    "df['credit_amount'] = more_raw_data.pop(5).astype(float)\n",
    "df['savings'] = more_raw_data.pop(6).str[1:].astype(float).replace({65:np.nan})\n",
    "df['savings'] -= df['savings'].min()\n",
    "df['savings'].value_counts(dropna=False)\n",
    "\n",
    "df['present_employment_since'] = more_raw_data.pop(7).str[1:].astype(float)\n",
    "df['present_employment_since'] -= df['present_employment_since'].min()\n",
    "\n",
    "df['installment_rate'] = more_raw_data.pop(8).astype(float)\n",
    "\n",
    "df['gender'] = more_raw_data[9].replace({\n",
    "    'A91':'male',\n",
    "    'A92': 'female',\n",
    "    'A93': 'male',\n",
    "    'A94': 'male',\n",
    "    'A95': 'female'\n",
    "})\n",
    "df['marital_status'] = more_raw_data[9].replace({\n",
    "    'A91': 'divorced/separated/married',\n",
    "    'A92': 'divorced/separated/married',\n",
    "    'A93': 'single',\n",
    "    'A94': 'divorced/separated/married',\n",
    "    'A95': 'single'\n",
    "})\n",
    "more_raw_data.drop(9,axis=1,inplace=True)\n",
    "\n",
    "df['other_debtors'] = more_raw_data.pop(10).replace({\n",
    "    'A101': 'none',\n",
    "    'A102': 'co-applicant',\n",
    "    'A103': 'guarantor'\n",
    "})\n",
    "\n",
    "df['residence_since'] = more_raw_data.pop(11).astype(float)\n",
    "df['property'] = more_raw_data.pop(12).replace({\n",
    "    'A121': 'real_estate',\n",
    "    'A122': 'building',\n",
    "    'A123': 'car or other',\n",
    "    'A124': 'unknown/none'\n",
    "})\n",
    "df['age'] = more_raw_data.pop(13).astype(float)\n",
    "\n",
    "df['other_installment_plans'] = more_raw_data.pop(14).replace({\n",
    "    'A141': 'bank',\n",
    "    'A142': 'stores',\n",
    "    'A143': 'none'\n",
    "})\n",
    "\n",
    "df['housing'] = more_raw_data.pop(15).replace({\n",
    "    'A151': 'rent',\n",
    "    'A152': 'own',\n",
    "    'A153': 'free'\n",
    "})\n",
    "\n",
    "df['n_credit_cards'] = more_raw_data.pop(16).astype(float)\n",
    "df['job'] = more_raw_data.pop(17).str[1:].astype(float)\n",
    "df['job'] -= df['job'].min()\n",
    "\n",
    "df['n_people_liable'] = more_raw_data.pop(18).astype(float)\n",
    "\n",
    "df['telephone'] = more_raw_data.pop(19).replace({\n",
    "    'A191': 'none',\n",
    "    'A192': 'yes'\n",
    "})\n",
    "\n",
    "df['foreign'] = more_raw_data.pop(20).replace({'A201':'yes','A202':'no'})\n",
    "\n",
    "df['y'] = more_raw_data[21].replace({'1': 'bad', '2':'good'})\n",
    "\n",
    "df.dropna().to_csv(output_folder_path+'german_credit.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "# ionospehere\n",
    "df = pd.read_fwf(folder_path + 'ionosphere.data', header = None)[0].str.split(',',expand=True)\n",
    "df.drop(1,inplace=True,axis=1)\n",
    "df.rename(columns = {df.columns[-1]:'y'},inplace=True)\n",
    "df['y'].replace({'g':'good','b':'bad'},inplace = True)\n",
    "df.dropna().to_csv(output_folder_path + 'ionosphere_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# kr-vs-kp\n",
    "df = pd.read_fwf(folder_path + 'kr-vs-kp.data',header = None)[0].str.split(',',expand=True)\n",
    "df['y'] = df.pop(df.columns[-1])\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'kr_vs_kp_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "# sonar\n",
    "df = pd.read_fwf(folder_path + 'sonar.all-data',header = None)[0].str.split(',',expand=True)\n",
    "df['y'] = df.pop(df.columns[-1]).replace({'R':'rock','M':'mine'})\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'sonar_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# balance scale\n",
    "df = pd.read_fwf(folder_path + 'balance-scale.data',header = None)[0].str.split(',',expand=True)\n",
    "df.columns = ['y','left_weight','left_distance','right_weight','right_distance']\n",
    "for feature in df.columns[1:]:\n",
    "    df[feature] = df[feature].astype(float)\n",
    "\n",
    "df['y'].replace({\n",
    "    'B':'balance',\n",
    "    'L':'left',\n",
    "    'R':'right'\n",
    "}, inplace = True)\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'balance_scale_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "# iris\n",
    "df = pd.read_fwf(folder_path + 'iris.data',header = None)[0].str.split(',',expand=True)\n",
    "df.columns = ['sepal_length','sepal_width','petal_length','petal_width','y']\n",
    "for feature in df.columns[:-1]:\n",
    "    df[feature] = df[feature].astype(float)\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'iris_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# lymphography\n",
    "raw_data = pd.read_fwf(folder_path + 'lymphography.data',header = None)[0].str.split(',',expand=True)\n",
    "raw_data.columns = np.arange(1,len(raw_data.columns)+1)\n",
    "df = pd.DataFrame()\n",
    "df['y'] = raw_data[1].replace({\n",
    "    '1':'normal',\n",
    "    '2':'metastases',\n",
    "    '3': 'malign',\n",
    "    '4': 'fibrosis'\n",
    "})\n",
    "\n",
    "df['lymphatics'] = raw_data[2].replace({\n",
    "    '1':'normal',\n",
    "    '2':'arched',\n",
    "    '3':'deformed',\n",
    "    '4':'displaced'\n",
    "})\n",
    "\n",
    "df['block_of_affere'] = raw_data[3].replace({\n",
    "    '1':'no',\n",
    "    '2':'yes'\n",
    "})\n",
    "df['block_of_lymph_c'] = raw_data[4].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['block_of_lymph_s'] = raw_data[5].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['by_pass'] = raw_data[6].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['extravasates'] = raw_data[7].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['regeneration'] = raw_data[8].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['early_uptake'] = raw_data[9].replace({\n",
    "    '1': 'no',\n",
    "    '2': 'yes'\n",
    "})\n",
    "df['lymph_nodes_dimin'] = raw_data[10].astype(float)\n",
    "df['lymph_nodes_enlar'] = raw_data[11].astype(float)\n",
    "df['chamges_in_lymph'] = raw_data[12].replace({\n",
    "    '1':'bean',\n",
    "    '2':'oval',\n",
    "    '3':'round'\n",
    "})\n",
    "\n",
    "df['defect_in_node'] = raw_data[13].replace({str(i+1):cat for i,cat in enumerate(['no', 'lacunar', 'lac. marginal', 'lac. central'])})\n",
    "df['change_in_node'] = raw_data[14].replace({str(i+1):cat for i,cat in enumerate(['no', 'lacunar', 'lac. marginal', 'lac. central'])})\n",
    "df['changes_in_stru'] = raw_data[15].replace({str(i+1):cat for i,cat in enumerate(['no', 'grainy', 'drop-like', 'coarse', 'diluted', 'reticular', 'stripped', 'faint'])})\n",
    "df['special_forms'] = raw_data[16].replace({str(i+1):cat for i,cat in enumerate(['no', 'chalices','vesicles'])})\n",
    "df['dislocation'] = raw_data[17].replace({str(i+1):cat for i,cat in enumerate(['no', 'yes'])})\n",
    "df['exclusion'] = raw_data[18].replace({str(i+1):cat for i,cat in enumerate(['no', 'yes'])})\n",
    "df['n_nodes'] = 4.5* (raw_data[19].astype(float)-1)*10\n",
    "\n",
    "df = df.loc[~df['y'].isin(['fibrosis','normal'])]\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'lymphography_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [],
   "source": [
    "# glass\n",
    "df = pd.read_fwf(folder_path + 'glass.data',header = None)[0].str.split(',',expand=True)\n",
    "df.drop(0,axis=1,inplace=True)\n",
    "df.columns = ['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','y']\n",
    "df['y'].replace({'':'4'},inplace=True)\n",
    "\n",
    "for feature in df.columns[:-1]:\n",
    "    df[feature] = df[feature].astype(float)\n",
    "\n",
    "df['y'].replace({\n",
    "   '1': 'building_windows_float_processed',\n",
    "   '2': 'building_windows_non_float_processed',\n",
    "   '3': 'vehicle_windows_float_processed',\n",
    "   '4': 'vehicle_windows_non_float_processed',\n",
    "   '5': 'containers',\n",
    "   '6': 'tableware',\n",
    "   '7': 'headlamps',\n",
    "},inplace=True)\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'glass.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "df_train = pd.read_fwf(folder_path + 'sat.trn',header = None)[0].str.split(' ',expand=True)\n",
    "df_test = pd.read_fwf(folder_path + 'sat.tst',header = None)[0].str.split(' ',expand=True)\n",
    "df = pd.concat([df_train,df_test])\n",
    "\n",
    "df['y'] = df.pop(df.columns[-1]).replace({\n",
    "'1': 'red_soil',\n",
    "'2': 'cotton_crop',\n",
    "'3': 'grey_soil',\n",
    "'4': 'damp_grey_soil',\n",
    "'5': 'soil_with_vegetation_stubble',\n",
    "'6': 'mixture_class',\n",
    "'7': 'very_damp_grey_soil'\n",
    "})\n",
    "\n",
    "df[df.columns[:-1]] = df[df.columns[:-1]].astype(float)\n",
    "df.dropna().to_csv(output_folder_path + 'satimage_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "# Image segmentation\n",
    "df_train = pd.read_fwf(folder_path + 'segmentation.data',header=None).loc[2:][0].str.split(',',expand=True)\n",
    "df_train.columns = ['y'] + list(df_train.loc[2])[:-1]\n",
    "df_train.drop(2,axis=0,inplace=True)\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "df_test = pd.read_fwf(folder_path + 'segmentation.test',header=None).loc[2:][0].str.split(',',expand=True)\n",
    "df_test.columns = ['y'] + list(df_test.loc[2])[:-1]\n",
    "df_test.drop(2,axis=0,inplace=True)\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df = pd.concat([df_train,df_test])\n",
    "df[df.columns[1:]] =df[df.columns[1:]].astype(float)\n",
    "df['y'] = df['y'].str.lower()\n",
    "df.dropna().to_csv(output_folder_path + 'segmentation_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [],
   "source": [
    "# zoo\n",
    "df = pd.read_fwf(folder_path + 'zoo.data',header=None)[0].str.split(',',expand=True)\n",
    "class_dict = df.groupby(df.columns[-1])[0].unique().apply(lambda l: ', '.join(l)).to_dict()\n",
    "df[df.columns[-1]].replace(class_dict,inplace=True)\n",
    "df.drop(0,axis=1,inplace=True)\n",
    "df.columns = ['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize','y']\n",
    "\n",
    "\n",
    "df['legs'] = df['legs'].astype(float)\n",
    "df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','tail','domestic','catsize']]=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','tail','domestic','catsize']].replace({'0':'false','1':'true'})\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'zoo_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "# letter recognition\n",
    "df = pd.read_fwf(folder_path + 'letter-recognition.data',header=None)[0].str.split(',',expand=True)\n",
    "y = df.pop(0)\n",
    "df.replace({'':np.nan},inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "for feature in df.columns:\n",
    "    df[feature] = df[feature].astype(float)\n",
    "\n",
    "df['y'] = y\n",
    "\n",
    "df.dropna().to_csv(output_folder_path + 'letter_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# loan prediction\n",
    "df = pd.read_csv(folder_path + 'loan_train.csv')\n",
    "df.drop('Loan_ID',axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Dependents'] = df['Dependents'].replace({'3+':'3'}).astype(float)\n",
    "df.dtypes\n",
    "\n",
    "df['y'] = df.pop('Loan_Status')\n",
    "\n",
    "df.to_csv(output_folder_path + 'loan_cleaned.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Boston housing\n",
    "df = pd.read_csv(folder_path + 'BostonHousing.csv')\n",
    "\n",
    "df['y'] = df.pop('medv')\n",
    "\n",
    "df.to_csv(output_folder_path + 'boston_housing.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# Black Friday\n",
    "df = pd.read_csv(folder_path + 'black_friday.csv')\n",
    "\n",
    "df.drop(['User_ID','Product_ID','Product_Category_1','Product_Category_2','Product_Category_3'],axis=1,inplace=True)\n",
    "\n",
    "df['Age'] = df['Age'].replace({age_range: age_group for age_group,age_range in enumerate(sorted(df['Age'].unique()))})\n",
    "\n",
    "import string\n",
    "df['Occupation'] = df['Occupation'].replace({number:letter for number,letter in enumerate(string.ascii_lowercase)})\n",
    "\n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].replace({range: group for group,range in enumerate(sorted(df['Stay_In_Current_City_Years'].unique()))})\n",
    "\n",
    "df['y'] = df.pop('Purchase')\n",
    "\n",
    "df.to_csv(output_folder_path + 'black_friday.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# Adult census\n",
    "df = pd.read_csv(folder_path + 'adult.csv')\n",
    "df.columns = [column.replace('.','_') for column in df.columns]\n",
    "df = df.replace({'?':None}).dropna()\n",
    "df.drop(['relationship','education'],axis=1,inplace=True)\n",
    "df['y'] = df.pop('income').replace({'>50K':'low','<=50K':'high'})\n",
    "\n",
    "df.to_csv(output_folder_path + 'income_census.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# titanic\n",
    "df = pd.read_csv(folder_path + 'titanic.csv')\n",
    "df['y'] = df.pop('Survived').replace({0:'no',1: 'yes'})\n",
    "df['n_family'] = df['SibSp'] + df['Parch']\n",
    "features = ['Pclass','Sex','Age','n_family','Fare','Embarked']\n",
    "df = df[features + ['y']].dropna()\n",
    "\n",
    "df.to_csv(output_folder_path + 'titanic.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# life expectancy\n",
    "df = pd.read_csv(folder_path + 'Life Expectancy Data.csv')\n",
    "df = df.loc[df['Year']==2015]\n",
    "df.drop(['Year','Country','Alcohol','Hepatitis B','Total expenditure'],axis=1,inplace=True)\n",
    "df['y'] = df.pop('Life expectancy ')\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv(output_folder_path + 'life_expectancy.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "# health insurance\n",
    "df = pd.read_csv(folder_path + 'insurance.csv')\n",
    "\n",
    "df['y'] = df.pop('charges')\n",
    "\n",
    "df.to_csv(output_folder_path + 'health_insurance.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "# concrete\n",
    "df = pd.read_csv(folder_path + 'Concrete_Data.csv')\n",
    "\n",
    "df['y'] = df.pop('strength')\n",
    "\n",
    "df.to_csv(output_folder_path + 'cement.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# online data sharing\n",
    "df = pd.read_csv(folder_path + 'OnlineNewsPopularity.csv')\n",
    "df.columns = [column[1:] for column in df.columns]\n",
    "\n",
    "data_channel_cols = [column for column in df.columns if column[:len('data_channel_is')]=='data_channel_is']\n",
    "df['data_channel'] = df[data_channel_cols].idxmax(axis=1).str[len('data_channel_is_'):]\n",
    "df.drop(data_channel_cols, axis=1, inplace=True)\n",
    "\n",
    "weekday_cols = [column for column in df.columns if column[:len('weekday_is_')]=='weekday_is_']\n",
    "df['weekday'] = df[weekday_cols].idxmax(axis=1).str[len('weekday_is_'):]\n",
    "df.drop(weekday_cols,axis=1,inplace=True)\n",
    "df.drop('is_weekend',axis=1,inplace=True)\n",
    "\n",
    "df['y'] = df.pop('shares')\n",
    "df.head()\n",
    "\n",
    "df.to_csv(output_folder_path + 'online_news.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_fwf(folder_path + 'auto-mpg.data', header = None)\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model_year','origin','car_name']\n",
    "df.replace({'?':None},inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype(float)\n",
    "\n",
    "df['y'] = df.pop('mpg')\n",
    "\n",
    "df.drop('car_name',axis=1,inplace=True)\n",
    "df.to_csv(output_folder_path + 'auto_mpg.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "df_red = pd.read_csv(folder_path + 'winequality-red.csv', sep = ';').assign(color='red')\n",
    "df_white = pd.read_csv(folder_path + 'winequality-white.csv', sep = ';').assign(color='white')\n",
    "\n",
    "df = pd.concat([df_red,df_white])\n",
    "df.index = range(len(df))\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df['y'] = df.pop('quality').astype(float)\n",
    "\n",
    "\n",
    "df.to_csv(output_folder_path + 'wine_quality.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n            ...\n            4888, 4889, 4890, 4891, 4892, 4893, 4894, 4895, 4896, 4897],\n           dtype='int64', length=6497)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_red,df_white]).index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4              0.70         0.00             1.9      0.076   \n1               7.8              0.88         0.00             2.6      0.098   \n2               7.8              0.76         0.04             2.3      0.092   \n3              11.2              0.28         0.56             1.9      0.075   \n4               7.4              0.70         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n6492            6.2              0.21         0.29             1.6      0.039   \n6493            6.6              0.32         0.36             8.0      0.047   \n6494            6.5              0.24         0.19             1.2      0.041   \n6495            5.5              0.29         0.30             1.1      0.022   \n6496            6.0              0.21         0.38             0.8      0.020   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n6492                 24.0                  92.0  0.99114  3.27       0.50   \n6493                 57.0                 168.0  0.99490  3.15       0.46   \n6494                 30.0                 111.0  0.99254  2.99       0.46   \n6495                 20.0                 110.0  0.98869  3.34       0.38   \n6496                 22.0                  98.0  0.98941  3.26       0.32   \n\n      alcohol  color    y  \n0         9.4    red  5.0  \n1         9.8    red  5.0  \n2         9.8    red  5.0  \n3         9.8    red  6.0  \n4         9.4    red  5.0  \n...       ...    ...  ...  \n6492     11.2  white  6.0  \n6493      9.6  white  5.0  \n6494      9.4  white  6.0  \n6495     12.8  white  7.0  \n6496     11.8  white  6.0  \n\n[6497 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>color</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>red</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>red</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>red</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>red</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>red</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6492</th>\n      <td>6.2</td>\n      <td>0.21</td>\n      <td>0.29</td>\n      <td>1.6</td>\n      <td>0.039</td>\n      <td>24.0</td>\n      <td>92.0</td>\n      <td>0.99114</td>\n      <td>3.27</td>\n      <td>0.50</td>\n      <td>11.2</td>\n      <td>white</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>6493</th>\n      <td>6.6</td>\n      <td>0.32</td>\n      <td>0.36</td>\n      <td>8.0</td>\n      <td>0.047</td>\n      <td>57.0</td>\n      <td>168.0</td>\n      <td>0.99490</td>\n      <td>3.15</td>\n      <td>0.46</td>\n      <td>9.6</td>\n      <td>white</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>6494</th>\n      <td>6.5</td>\n      <td>0.24</td>\n      <td>0.19</td>\n      <td>1.2</td>\n      <td>0.041</td>\n      <td>30.0</td>\n      <td>111.0</td>\n      <td>0.99254</td>\n      <td>2.99</td>\n      <td>0.46</td>\n      <td>9.4</td>\n      <td>white</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>6495</th>\n      <td>5.5</td>\n      <td>0.29</td>\n      <td>0.30</td>\n      <td>1.1</td>\n      <td>0.022</td>\n      <td>20.0</td>\n      <td>110.0</td>\n      <td>0.98869</td>\n      <td>3.34</td>\n      <td>0.38</td>\n      <td>12.8</td>\n      <td>white</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>6.0</td>\n      <td>0.21</td>\n      <td>0.38</td>\n      <td>0.8</td>\n      <td>0.020</td>\n      <td>22.0</td>\n      <td>98.0</td>\n      <td>0.98941</td>\n      <td>3.26</td>\n      <td>0.32</td>\n      <td>11.8</td>\n      <td>white</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6497 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
